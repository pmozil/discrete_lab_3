{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zL_PfXjVw-1S"
      },
      "source": [
        "# Colab setup\n",
        "## The first step is not neccesary now, as I fixed all the bad errors\n",
        "1. Install python 3.10. Please reload page (Ctrl + r / F5) after the first cell\n",
        "2. Then, clone the repo into the colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TW7kAF30w-1W"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/korakot/kora/releases/download/v0.10/py310.sh\n",
        "!bash ./py310.sh -b -f -p /usr/local\n",
        "!python -m ipykernel install --name \"py310\" --user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuCcdNS5w-1X",
        "outputId": "0f808fc0-dc55-40a4-c81b-e2227877309b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'discrete_lab_3'...\n",
            "remote: Enumerating objects: 90, done.\u001b[K\n",
            "remote: Counting objects: 100% (90/90), done.\u001b[K\n",
            "remote: Compressing objects: 100% (66/66), done.\u001b[K\n",
            "remote: Total 90 (delta 43), reused 67 (delta 20), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (90/90), 103.89 KiB | 2.16 MiB/s, done.\n",
            "/content/discrete_lab_3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 1)) (0.10.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 2)) (3.2.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 3)) (3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 4)) (1.21.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 5)) (1.3.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 6)) (1.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 7)) (4.64.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->-r requirements.txt (line 2)) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->-r requirements.txt (line 2)) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->-r requirements.txt (line 2)) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->-r requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->-r requirements.txt (line 5)) (2022.7.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->-r requirements.txt (line 6)) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->-r requirements.txt (line 6)) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->-r requirements.txt (line 6)) (3.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib->-r requirements.txt (line 2)) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/pmozil/discrete_lab_3\n",
        "%cd discrete_lab_3\n",
        "!python -m pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPTGwbXJw-1Y",
        "outputId": "65e97f55-b916-41c3-8db5-3c31e859681e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'graphs'\n",
            "/content/discrete_lab_3/graphs\n"
          ]
        }
      ],
      "source": [
        "%cd graphs\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import animation\n",
        "import queue\n",
        "import heapq\n",
        "import time\n",
        "from sklearn import datasets\n",
        "\n",
        "from tqdm import tqdm\n",
        "from itertools import product\n",
        "from typing import Tuple, Iterator, List\n",
        "from sklearn.tree import (\n",
        "    DecisionTreeClassifier as SklearnDecisionTreeClassifier,\n",
        ")\n",
        "\n",
        "from graph_generation import gnp_random_connected_graph, draw_graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lx62XgOmw-1Z"
      },
      "source": [
        "# Prim's algorithm\n",
        "Here's a naive implementation using a binary heap. It's logarithmic, at least"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FzcklxiCw-1a"
      },
      "outputs": [],
      "source": [
        "def prim(graph: nx.Graph) -> nx.Graph:\n",
        "    \"\"\"\n",
        "    Create a spanning tree for the graph\n",
        "\n",
        "    Args:\n",
        "        graph: nx.Graph - the given graph\n",
        "\n",
        "    Returns:\n",
        "        nx.Graph - the spanning tree\n",
        "    \"\"\"\n",
        "    pqueue = []\n",
        "    nodes = graph.nodes()\n",
        "    spanning_tree = nx.Graph()\n",
        "    for edge in graph.edges(data=True):\n",
        "        heapq.heappush(pqueue, (edge[0], edge[1]))\n",
        "    visited = [0 for _ in nodes]\n",
        "    min_edge = heapq.heappop(pqueue)\n",
        "    spanning_tree.add_edge(*min_edge)\n",
        "    visited[min_edge[0]] = 1\n",
        "    visited[min_edge[1]] = 1\n",
        "    while not pqueue and not all(visited):\n",
        "        min_edge = heapq.heappop(pqueue)\n",
        "        if (visited[min_edge[0]]) ^ (visited[min_edge[1]]):\n",
        "            spanning_tree.add_edge(*min_edge)\n",
        "            visited[min_edge[0]] = 1\n",
        "            visited[min_edge[1]] = 1\n",
        "    return spanning_tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sX2I7-20w-1a"
      },
      "source": [
        "A bit slow, but it'll do. On to comparing it with the networkx algorithm!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xDQ9aNNw-1b",
        "outputId": "eee7313f-fbce-4358-ce20-e135dbcf42fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:21<00:00,  4.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "native: 0.030673773288726808s\n",
            "networkx: 0.0701137638092041s\n",
            "relative: 0.43748576060183125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "ITERATIONS = 100\n",
        "time_taken_networkx = 0\n",
        "time_taken_native = 0\n",
        "for i in tqdm(range(ITERATIONS)):\n",
        "    G = gnp_random_connected_graph(250, 0.2)\n",
        "    start = time.time()\n",
        "    nx.minimum_spanning_tree(G, algorithm=\"prim\")\n",
        "    end = time.time()\n",
        "\n",
        "    time_taken_networkx += end - start\n",
        "\n",
        "    start = time.time()\n",
        "    prim(G)\n",
        "    end = time.time()\n",
        "\n",
        "    time_taken_native += end - start\n",
        "\n",
        "time_taken_native = time_taken_native / ITERATIONS\n",
        "time_taken_networkx = time_taken_networkx / ITERATIONS\n",
        "\n",
        "print(f\"native: {time_taken_native}s\")\n",
        "print(f\"networkx: {time_taken_networkx}s\")\n",
        "print(f\"relative: {time_taken_native / time_taken_networkx}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUms1Fnyw-1c"
      },
      "source": [
        "## TODO: add kruskal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKCz1uwdw-1d"
      },
      "source": [
        "# Floyd's algorithm\n",
        "On to the Floyd's algorithm now. Here's out code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "eOyJgsqzw-1e"
      },
      "outputs": [],
      "source": [
        "def floyd(graph: nx.Graph) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Calculate the distance matrix for a graph\n",
        "\n",
        "    Args:\n",
        "        graph: nx.Graph - the directed graph\n",
        "\n",
        "    Returns:\n",
        "        tuple[np.ndarray, np.ndarray] - the W and Θ matrixes\n",
        "    \"\"\"\n",
        "    graph = graph.to_directed()\n",
        "    nodes = np.intp(graph.number_of_nodes())\n",
        "    distances = nx.to_numpy_array(graph, None, weight=\"weight\", nonedge=np.inf)\n",
        "    np.fill_diagonal(distances, 0)\n",
        "    source_nodes = np.zeros_like(distances)\n",
        "\n",
        "    for k in range(nodes):\n",
        "        if any(distances[i, i] < 0 for i in range(nodes)):\n",
        "            print(\"Negative cycle in the graph!\")\n",
        "            raise ValueError\n",
        "        dist_fst = distances[k]\n",
        "        for i in range(nodes):\n",
        "            dist_snd = distances[i]\n",
        "            for j in range(nodes):\n",
        "                new_val = dist_snd[k] + dist_fst[j]\n",
        "                if new_val < distances[i, j]:\n",
        "                    distances[i, j] = new_val\n",
        "                    source_nodes[j, i] = k\n",
        "\n",
        "    return distances, source_nodes\n",
        "\n",
        "\n",
        "def floyd_with_numpy(graph: nx.Graph) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Calculate the distance matrix for a graph, with numpy minimum\n",
        "        (it should be faster)\n",
        "\n",
        "    Args:\n",
        "        graph: nx.Graph - the directed graph\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray - the W and Θ matrixes\n",
        "    \"\"\"\n",
        "    graph = graph.to_directed()\n",
        "    distances = nx.to_numpy_array(graph, None, weight=\"weight\", nonedge=np.inf)\n",
        "    np.fill_diagonal(distances, 0)\n",
        "\n",
        "    for i in range(distances.shape[0]):\n",
        "        distances = np.minimum(\n",
        "            distances,\n",
        "            distances[i, :][np.newaxis, :] + distances[:, i][:, np.newaxis],\n",
        "        )\n",
        "\n",
        "    return distances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvWJlWwDw-1f"
      },
      "source": [
        "I shamelessly stole the second one from the networkx code. It's ingenious!a\n",
        "Still like 2x slower than the networkx implementation, even though the code is identicalo\n",
        "Let's look at the times:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9FcXLltw-1f"
      },
      "outputs": [],
      "source": [
        "\n",
        "ITERATIONS = 1000\n",
        "time_taken_networkx = 0\n",
        "time_taken_native = 0\n",
        "for i in tqdm(range(ITERATIONS)):\n",
        "    G = gnp_random_connected_graph(40, 0.2)\n",
        "    if nx.negative_edge_cycle(G):\n",
        "        continue\n",
        "    start = time.time()\n",
        "    a = nx.floyd_warshall_numpy(G)\n",
        "    end = time.time()\n",
        "\n",
        "    time_taken_networkx += end - start\n",
        "\n",
        "    start = time.time()\n",
        "    b = floyd_with_numpy(G)\n",
        "    end = time.time()\n",
        "\n",
        "    time_taken_native += end - start\n",
        "\n",
        "time_taken_native = time_taken_native / ITERATIONS\n",
        "time_taken_networkx = time_taken_networkx / ITERATIONS\n",
        "\n",
        "print(f\"native: {time_taken_native}s\")\n",
        "print(f\"networkx: {time_taken_networkx}s\")\n",
        "print(f\"relative: {time_taken_native / time_taken_networkx}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9NicRmfw-1f"
      },
      "source": [
        "# Time complexities and plots\n",
        "Plotting stuff on a cartesian plane is almost like mediation, so let's do that"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "or9ugQTWw-1f",
        "outputId": "53ba23e5-e9cf-42fe-eab5-2cdcce2943ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 62/62 [00:46<00:00,  1.34it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f6581a3b9a0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "counts = list(range(10, 1000, 16))\n",
        "times = []\n",
        "for vert in tqdm(counts): # Vertice counts\n",
        "    grp = gnp_random_connected_graph(vert, 100)\n",
        "    start = time.time()\n",
        "    prim(grp)\n",
        "    times.append(time.time() - start)\n",
        "plt.scatter(counts, times)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Say fot the outliars with tons of vertices, it's logarithmic.\n",
        "Same goes for the floyd's algoritm (I'll be using numpy, so as not to die of olt age while running this)"
      ],
      "metadata": {
        "id": "TKll0lVgzZdd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "counts = list(range(10, 1000, 16))\n",
        "times = []\n",
        "for vert in tqdm(counts): # Vertice counts\n",
        "    grp = gnp_random_connected_graph(vert, 100)\n",
        "    start = time.time()\n",
        "    floyd_with_numpy(grp)\n",
        "    times.append(time.time() - start)\n",
        "plt.scatter(counts, times)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "0FIkuo9Ez75u",
        "outputId": "8f3a4122-468f-4396-f432-1a961a4cf41e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 62/62 [04:09<00:00,  4.03s/it]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f65805d2940>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "... Now imagine that the non-numpy one runs 80x slower >:-[. \n",
        "Anyways, it's ± cubic, as expected. You could calculate to be sure but nah..."
      ],
      "metadata": {
        "id": "tC1_jxpQ018t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision trees\n",
        "\n",
        "Now, the algorithm for the decision tree is fairly simple: pick the column, which has the best distribution of results (by distribution here i mean that the probability of landing on an expected value after comparing the threshold is high. For that one may use entropy or gini, or something more complicated, but for our simple case simple gini will suffice), and set it as the next node.\n",
        "Anything below the threshold goes left, and anythig above it goes right. Repeat the process until the tree max depth is reached, and be happy. That's it\n",
        "\n",
        "Now, on to the code"
      ],
      "metadata": {
        "id": "NVhIA26G1ZNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "    \"\"\"A decision tree node.\n",
        "\n",
        "    Parameters:\n",
        "        gini: float - the node's gini value\n",
        "        samples: int - the amount of samples used for fitting\n",
        "        samples_per_self: int - the same as samples,\n",
        "            but filters bad data\n",
        "        targets: np.ndarray - the class to be predicted\n",
        "        threshold: float - the criterion for going left or right\n",
        "        left: Node | None - the left leaf\n",
        "        right: Node | Node - the right leaf\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        gini: float,\n",
        "        samples: int,\n",
        "        samples_per_self: list,\n",
        "        targets: np.intp\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Init for the Node class\n",
        "\n",
        "        Args:\n",
        "            gini: float - the node's gini value\n",
        "            samples: int - the amount of samples used for fitting\n",
        "            samples_per_self: int - the same as samples,\n",
        "                but filters bad data\n",
        "            targets: np.ndarray - the class to be predicted\n",
        "        \"\"\"\n",
        "        self.gini = gini\n",
        "        self.samples = samples\n",
        "        self.samples_per_self = samples_per_self\n",
        "        self.targets: np.intp = targets\n",
        "        self._feature_index: int = 0\n",
        "        self._threshold = 0\n",
        "        self._left = None\n",
        "        self._right = None\n",
        "\n",
        "    def print_gini(self):\n",
        "        print(self.gini)\n",
        "        if self._left is not None:\n",
        "            self._left.print_gini()\n",
        "        if self._right is not None:\n",
        "            self._right.print_gini()\n",
        "\n",
        "\n",
        "    @property\n",
        "    def feature_index(self) -> int:\n",
        "        \"\"\"\n",
        "        Getter for self.feature_index\n",
        "        \"\"\"\n",
        "        return self._feature_index\n",
        "\n",
        "    @feature_index.setter\n",
        "    def feature_index(self, feature_index: int) -> None:\n",
        "        \"\"\"\n",
        "        Setter for feature_index\n",
        "\n",
        "        Args:\n",
        "            feature_index: float\n",
        "        \"\"\"\n",
        "        self._feature_index = feature_index\n",
        "\n",
        "    @property\n",
        "    def threshold(self) -> float:\n",
        "        \"\"\"\n",
        "        Getter for self._threshold\n",
        "        \"\"\"\n",
        "        return self._threshold\n",
        "\n",
        "    @threshold.setter\n",
        "    def threshold(self, threshold: float) -> None:\n",
        "        \"\"\"\n",
        "        Setter for self._threshold\n",
        "\n",
        "        Args:\n",
        "            threshold: float\n",
        "        \"\"\"\n",
        "        self._threshold = threshold\n",
        "\n",
        "    @property\n",
        "    def left(self) -> \"Node\":\n",
        "        \"\"\"\n",
        "        Getter for self._left\n",
        "        \"\"\"\n",
        "        return self._left\n",
        "\n",
        "    @left.setter\n",
        "    def left(self, left: \"Node\") -> None:\n",
        "        \"\"\"\n",
        "        Setter for self._left\n",
        "\n",
        "        Args:\n",
        "            left: Node | None\n",
        "        \"\"\"\n",
        "        self._left = left\n",
        "\n",
        "    @property\n",
        "    def right(self) -> \"Node\":\n",
        "        \"\"\"\n",
        "        Getter for self._right\n",
        "        \"\"\"\n",
        "        return self._right\n",
        "\n",
        "    @right.setter\n",
        "    def right(self, right: \"Node\") -> None:\n",
        "        \"\"\"\n",
        "        Setter for self._right\n",
        "\n",
        "        Args:\n",
        "            right: Node | None\n",
        "        \"\"\"\n",
        "        self._right = right"
      ],
      "metadata": {
        "id": "KWF8nqrO2Nki"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Be not afraid, that's just the setters/getters for the node. Otherwise, the class is fairly simple. Now, on to the tree itself"
      ],
      "metadata": {
        "id": "wauHZ1rY2TPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecisionTreeClassifier:\n",
        "    def __init__(self, max_depth: int = 16, min_predictions: int = 20) -> None:\n",
        "        self._max_depth = max_depth\n",
        "        self._min_predictions = min_predictions\n",
        "\n",
        "    def fit(self, features: np.ndarray, targets: np.ndarray) -> None:\n",
        "        \"\"\"\n",
        "        Grow the tree from given data\n",
        "\n",
        "        Args:\n",
        "            features: np.ndarray - the array of features\n",
        "            targets: np.ndarray - the araay of features to split by\n",
        "        \"\"\"\n",
        "        # classes are assumed to go from 0 to n-1\n",
        "        self._classes = len(set(targets))\n",
        "        self._features_len = features.shape[1]\n",
        "        self._features = features\n",
        "        self._targets = targets\n",
        "        self._tree = self.build_tree(features, targets)\n",
        "\n",
        "    def predict(self, object_features: np.ndarray) -> list:\n",
        "        \"\"\"\n",
        "        Predict the value for given features\n",
        "\n",
        "        Args:\n",
        "            object_features: np.ndarray - the features of specific object\n",
        "        \"\"\"\n",
        "        return [self._predict(inputs) for inputs in object_features]\n",
        "\n",
        "    def _gini(self, targets):\n",
        "        \"\"\"Compute Gini for a node.\n",
        "\n",
        "        Args:\n",
        "            targets: np.ndarray\n",
        "        \"\"\"\n",
        "        m = targets.size\n",
        "        return 1.0 - sum(\n",
        "            (np.sum(targets == c) / m) ** 2 for c in range(self._classes)\n",
        "        )\n",
        "\n",
        "    def split_data(\n",
        "        self, features: np.ndarray, targets: np.ndarray\n",
        "    ) -> Tuple[int, float]:\n",
        "        \"\"\"Find the best split for a node.\n",
        "\n",
        "        Args:\n",
        "            features: np.ndarray - the array of features\n",
        "            targets: np.ndarray - the array of targets (results)\n",
        "\n",
        "        Returns:\n",
        "            tuple[int, float] - the pair with the index of\n",
        "                feature and threshold\n",
        "        \"\"\"\n",
        "        m = targets.size\n",
        "        if m <= 1:\n",
        "            return -1, -1\n",
        "\n",
        "        parent_counts = [np.sum(targets == c) for c in range(self._classes)]\n",
        "\n",
        "        best_gini = 1.0 - sum((n / m) ** 2 for n in parent_counts)\n",
        "        id, thr = -1, -1\n",
        "\n",
        "        for idx in range(self._features_len):\n",
        "            thresholds, classes = zip(*sorted(zip(features[:, idx], targets)))\n",
        "\n",
        "            lefts = [0] * self._classes\n",
        "            rights = parent_counts.copy()\n",
        "            for i in range(1, m):\n",
        "                c = int(classes[i - 1])\n",
        "                lefts[c] += 1\n",
        "                rights[c] -= 1\n",
        "                gini_left = 1.0 - sum(\n",
        "                    (lefts[x] / i) ** 2 for x in range(self._classes)\n",
        "                )\n",
        "                gini_right = 1.0 - sum(\n",
        "                    (rights[x] / (m - i)) ** 2 for x in range(self._classes)\n",
        "                )\n",
        "\n",
        "                gini = (i * gini_left + (m - i) * gini_right) / m\n",
        "\n",
        "                if thresholds[i] == thresholds[i - 1]:\n",
        "                    continue\n",
        "\n",
        "                if gini < best_gini:\n",
        "                    best_gini = gini\n",
        "                    id = idx\n",
        "                    thr = (thresholds[i] + thresholds[i - 1]) / 2\n",
        "\n",
        "        return id, float(thr)\n",
        "\n",
        "    def build_tree(\n",
        "        self, features: np.ndarray, targets: np.ndarray, depth: int = 0\n",
        "    ) -> Node:\n",
        "        \"\"\"\n",
        "        Recursively construct the tree\n",
        "\n",
        "        Args:\n",
        "            features: np.ndarray - the array of features\n",
        "            target: np.ndarray - the array of targets (results)\n",
        "            depth: int - the current tree depth\n",
        "        \"\"\"\n",
        "        samples_per_self = [np.sum(targets == i) for i in range(self._classes)]\n",
        "        preds = np.argmax(samples_per_self)\n",
        "        node = Node(\n",
        "            gini=self._gini(targets),\n",
        "            samples=targets.size,\n",
        "            samples_per_self=samples_per_self,\n",
        "            targets=preds,\n",
        "        )\n",
        "\n",
        "        if (\n",
        "            depth < self._max_depth\n",
        "            and samples_per_self[preds] >= self._min_predictions\n",
        "        ):\n",
        "            idx, thr = self.split_data(features, targets)\n",
        "            indices_left = features[:, idx] < thr\n",
        "            features_left, targets_left = (\n",
        "                features[indices_left],\n",
        "                targets[indices_left],\n",
        "            )\n",
        "            features_right, targets_right = (\n",
        "                features[~indices_left],\n",
        "                targets[~indices_left],\n",
        "            )\n",
        "            node.feature_index = idx\n",
        "            node.threshold = thr\n",
        "            node.left = self.build_tree(features_left, targets_left, depth + 1)\n",
        "            node.right = self.build_tree(\n",
        "                features_right, targets_right, depth + 1\n",
        "            )\n",
        "        return node\n",
        "\n",
        "    @property\n",
        "    def accuracy(self) -> float:\n",
        "        \"\"\"\n",
        "        Evaluate the tree's accuracy\n",
        "\n",
        "        Returns:\n",
        "            float: the tree's accuracy\n",
        "        \"\"\"\n",
        "        if self._tree is None:\n",
        "            return 0\n",
        "        num_guessed = 0\n",
        "        for ind, input in enumerate(self._features):\n",
        "            pred = self.predict([input])[0]\n",
        "            if pred == self._targets[ind]:\n",
        "                num_guessed += 1\n",
        "        return num_guessed / len(self._targets)\n",
        "\n",
        "    def _predict(self, object_features: np.ndarray) -> np.intp:\n",
        "        \"\"\"\n",
        "        Predict the class for a single sample\n",
        "\n",
        "        Args:\n",
        "            object_features: np.ndarray - the features of a single object\n",
        "        \"\"\"\n",
        "        if self._tree is None:\n",
        "            raise ValueError\n",
        "        node = self._tree\n",
        "        while node.left is not None:\n",
        "            node = (\n",
        "                node.left\n",
        "                if object_features[node.feature_index] < node.threshold\n",
        "                else node.right\n",
        "            )\n",
        "        return node.targets"
      ],
      "metadata": {
        "id": "ev7RGiIo4O8j"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Everything should be quite straightforward, if only for the recursive tree growing. In it, we split the given features by the threshold, and, as already mentioned, we feed the values below the threshold to the node on the left, and all the other data (see `features[~indices_left]`) to the node on the right.\n",
        "There's also an guesser for the optimal tree values (max_depth and min_predictions), but it's really just bruteforcing, so i'll just leave it here"
      ],
      "metadata": {
        "id": "7RVAByYT4Px8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Estimator:\n",
        "    def __init__(\n",
        "        self,\n",
        "        features: np.ndarray,\n",
        "        targets: np.ndarray,\n",
        "        min_predictions: List[int] = [5, 10, 20],\n",
        "        max_depth: List[int] = [3, 5, 10, 16],\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Init fot eh Estimator\n",
        "\n",
        "        Args:\n",
        "        \"\"\"\n",
        "        self.min_predictions = min_predictions\n",
        "        self.max_depth = max_depth\n",
        "        self.features = features\n",
        "        self.targets = targets\n",
        "\n",
        "    @property\n",
        "    def _next_tree(self) -> Iterator[DecisionTreeClassifier]:\n",
        "        \"\"\"\n",
        "        Train the next Tree so as to check all their accuracies\n",
        "\n",
        "        Returns:\n",
        "            DecisionTreeClassifier - the next tree with the new arguments\n",
        "        \"\"\"\n",
        "        for depth, preds in product(self.max_depth, self.min_predictions):\n",
        "            tree = DecisionTreeClassifier(\n",
        "                max_depth=depth,\n",
        "                min_predictions=preds,\n",
        "            )\n",
        "            tree.fit(self.features, self.targets)\n",
        "            yield tree\n",
        "\n",
        "    @property\n",
        "    def best_tree(self) -> DecisionTreeClassifier:\n",
        "        \"\"\"\n",
        "        Find best tree for the given predictions and depths\n",
        "\n",
        "        Returns:\n",
        "            DecisionTreeClassifier - the best tree\n",
        "        \"\"\"\n",
        "        trees = self._next_tree\n",
        "        accuracy = -1\n",
        "        for tree in trees:\n",
        "            if tree.accuracy > accuracy:\n",
        "                cur_tree = tree\n",
        "                accuracy = tree.accuracy\n",
        "        return cur_tree"
      ],
      "metadata": {
        "id": "t2zXNX-d5HOg"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how it all works. We'll be using the breast cancer dataset. It has plenty of features, and is sufficiently big for our use case"
      ],
      "metadata": {
        "id": "G1RCYML_5LxC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets.load_breast_cancer()\n",
        "feats, targets = dataset.data, dataset.target\n",
        "\n",
        "estimator = Estimator(\n",
        "    features=feats,\n",
        "    targets=targets,\n",
        "    max_depth=list(range(2, 10)),\n",
        "    min_predictions=list(range(2, 20, 4))\n",
        ")\n",
        "\n",
        "clf_sklearn = SklearnDecisionTreeClassifier()\n",
        "clf_sklearn.fit(feats, targets)\n",
        "\n",
        "clf = estimator.best_tree\n",
        "print(f\"Tree accuracy: {clf.accuracy}\")\n",
        "count = 0\n",
        "for _ in range(1000):\n",
        "    input = [np.random.rand() for _ in range(30)]\n",
        "    pred = clf.predict([input])[0]\n",
        "    pred_sklearn = clf_sklearn.predict([input])[0]\n",
        "#     print(\n",
        "#         f\"\"\"\n",
        "# Prediction: {dataset.target_names[pred]}; \\\n",
        "# Sklearn prediction: {dataset.target_names[pred_sklearn]}\n",
        "#     \"\"\"\n",
        "#     )\n",
        "    if pred == pred_sklearn:\n",
        "        count += 1\n",
        "print(f\"Accuracy (compared with the sklearn tree): {count / 1000}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Rv2XfcO7hkv",
        "outputId": "c924a860-f4ea-4600-e6e1-9f0b1671026e"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-46-6f9c2bd1a73f>:38: RuntimeWarning: invalid value encountered in long_scalars\n",
            "  (np.sum(targets == c) / m) ** 2 for c in range(self._classes)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tree accuracy: 1.0\n",
            "Accuracy (compared with the sklearn tree): 0.979\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}